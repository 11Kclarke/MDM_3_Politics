{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_spss('data.sav')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is the extraction of the questions from the original data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for col in df.columns:\n",
    "    \n",
    "    answersforcol =[]\n",
    "    count = 0\n",
    "    for i in df[col]:\n",
    "        i=str(i)\n",
    "        if i not in answersforcol and not i.isdigit() and \".\" not in i:#is digit removes ints . removes floats if someones put a . in there written answer fuckem\n",
    "            answersforcol.append(i)\n",
    "    \n",
    "        if i not in answers and not i.isdigit() and \".\" not in i:\n",
    "            answers.append(i)\n",
    "        count+=1\n",
    "        if count > 300:\n",
    "            break\n",
    "    #print(\"potential answers for \"+str(col))\n",
    "    #print(answersforcol)\n",
    "\n",
    "#print(\"total list of answers:\")\n",
    "#print(answers)\n",
    "#prefixes = ['Fairly likely','Very likely','Very unlikely', 'Fairly unlikely',\"Don't know\",'Neither likely nor unlikely','A little','Not at all','Not very strong', 'nan', 'Very strong', 'Fairly strong', \"Don't know\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "economy_list = ['deficitReduce','overseasAid','changeEconomy','econGenRetro','econPersonalRetro','economyResponsible','selfPriorities_econ']\n",
    "enviornment_list = ['climateChange','enviroGrowth','selfPriorities_environment']\n",
    "immig_list = ['immigCultural','immigSelf','changeImmig','immigEcon','controlImmig']\n",
    "health_list = ['selfPriorities_nhs','effectsEUNHS','changeNHS']\n",
    "brexit_list = ['EUIntegrationSelf','cantLiveWithEU_1','cantLiveWithEU_2','cantLiveWithEU_3','cantLiveWithEU_4','selfPriorities_brexit','euRefVote','dealVremain','remainVnodeal','effectsEUUnemployment','effectsEUTrade','effectsEUImmigration','effectsEUTerror','effectsEUEcon','dealGoodBad','happyEULeave','euID','euRefDoOver','cancelBrexit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['partyId', 'deficitReduce', 'overseasAid', 'changeEconomy', 'econGenRetro', 'econPersonalRetro', 'economyResponsible', 'selfPriorities_econ', 'climateChange', 'enviroGrowth', 'selfPriorities_environment', 'immigCultural', 'immigSelf', 'changeImmig', 'immigEcon', 'controlImmig', 'selfPriorities_nhs', 'effectsEUNHS', 'changeNHS', 'EUIntegrationSelf', 'cantLiveWithEU_1', 'cantLiveWithEU_2', 'cantLiveWithEU_3', 'cantLiveWithEU_4', 'selfPriorities_brexit', 'euRefVote', 'dealVremain', 'remainVnodeal', 'effectsEUUnemployment', 'effectsEUTrade', 'effectsEUImmigration', 'effectsEUTerror', 'effectsEUEcon', 'dealGoodBad', 'happyEULeave', 'euID', 'euRefDoOver', 'cancelBrexit']\n"
     ]
    }
   ],
   "source": [
    "total_list = [economy_list,enviornment_list,immig_list,health_list,brexit_list]\n",
    "flat_list = [item for l in total_list for item in l]\n",
    "flat_list.insert(0,'partyId')\n",
    "print(flat_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = df.loc[:,flat_list]\n",
    "extracted_data.columns= extracted_data.columns.str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data.to_csv('extractd_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of code is preparing the data for use with k-modes, to see how the data clusters initially - K-modes uses a dissimalarity method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we want to replace each of the NaN values with an unambiguous category, for example Don't know or impartial.... This has to be done manually for each value with a NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "economyresponsible\n",
      "remainvnodeal\n",
      "Index(['partyid', 'deficitreduce', 'overseasaid', 'changeeconomy',\n",
      "       'econgenretro', 'econpersonalretro', 'economyresponsible',\n",
      "       'selfpriorities_econ', 'climatechange', 'envirogrowth',\n",
      "       'selfpriorities_environment', 'immigcultural', 'immigself',\n",
      "       'changeimmig', 'immigecon', 'controlimmig', 'selfpriorities_nhs',\n",
      "       'effectseunhs', 'changenhs', 'euintegrationself', 'cantlivewitheu_1',\n",
      "       'cantlivewitheu_2', 'cantlivewitheu_3', 'cantlivewitheu_4',\n",
      "       'selfpriorities_brexit', 'eurefvote', 'dealvremain', 'remainvnodeal',\n",
      "       'effectseuunemployment', 'effectseutrade', 'effectseuimmigration',\n",
      "       'effectseuterror', 'effectseuecon', 'dealgoodbad', 'happyeuleave',\n",
      "       'euid', 'eurefdoover', 'cancelbrexit'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for col in extracted_data.columns:\n",
    "    try:\n",
    "        extracted_data[col] = extracted_data[col].fillna(\"Don't know\")#we should centre our numerical stuff about 0\n",
    "    except:\n",
    "        print(col)\n",
    "extracted_data['remainvnodeal'] = extracted_data['remainvnodeal'].replace(9999.0, \"Don't know\") \n",
    "extracted_data['remainvnodeal'] = extracted_data['remainvnodeal'].fillna(\"Don't know\")\n",
    "print(extracted_data.columns)\n",
    "originaldata = extracted_data  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have no NaN values as evidenced bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "partyid                       0\n",
       "deficitreduce                 0\n",
       "overseasaid                   0\n",
       "changeeconomy                 0\n",
       "econgenretro                  0\n",
       "econpersonalretro             0\n",
       "economyresponsible            0\n",
       "selfpriorities_econ           0\n",
       "climatechange                 0\n",
       "envirogrowth                  0\n",
       "selfpriorities_environment    0\n",
       "immigcultural                 0\n",
       "immigself                     0\n",
       "changeimmig                   0\n",
       "immigecon                     0\n",
       "controlimmig                  0\n",
       "selfpriorities_nhs            0\n",
       "effectseunhs                  0\n",
       "changenhs                     0\n",
       "euintegrationself             0\n",
       "cantlivewitheu_1              0\n",
       "cantlivewitheu_2              0\n",
       "cantlivewitheu_3              0\n",
       "cantlivewitheu_4              0\n",
       "selfpriorities_brexit         0\n",
       "eurefvote                     0\n",
       "dealvremain                   0\n",
       "remainvnodeal                 0\n",
       "effectseuunemployment         0\n",
       "effectseutrade                0\n",
       "effectseuimmigration          0\n",
       "effectseuterror               0\n",
       "effectseuecon                 0\n",
       "dealgoodbad                   0\n",
       "happyeuleave                  0\n",
       "euid                          0\n",
       "eurefdoover                   0\n",
       "cancelbrexit                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracted_data.isna().sum()\n",
    "originaldata.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some data exploration of the representation of each party, as well as seeing how the questions may split each of them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential answers for partyid\n",
      "['Labour', 'No - none', 'Liberal Democrat', 'Conservative', 'Plaid Cymru', 'Brexit Party', \"Don't know\", 'Green Party', 'Scottish National Party (SNP)', 'Other']\n",
      "potential answers for deficitreduce\n",
      "[\"Don't know\", 'It is important but not absolutely  necessary', 'It is not necessary but it would be desirable', 'It is completely necessary', 'It is completely unnecessary']\n",
      "potential answers for overseasaid\n",
      "['Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Agree', 'Strongly disagree', \"Don't know\"]\n",
      "potential answers for changeeconomy\n",
      "['Getting a lot worse', 'Staying about the same', 'Getting a little worse', 'Getting a lot better', \"Don't know\", 'Getting a little better']\n",
      "potential answers for econgenretro\n",
      "['Got a little worse', 'Stayed the same', 'Got a lot worse', \"Don't know\", 'Got a little better']\n",
      "potential answers for econpersonalretro\n",
      "['Got a little worse', 'Stayed the same', \"Don't know\", 'Got a little better', 'Got a lot worse', 'Got a lot better']\n",
      "potential answers for economyresponsible\n",
      "['A great deal', 'A moderate amount', 'Don\\x92t know', 'A lot', 'A little', 'Not at all']\n",
      "potential answers for selfpriorities_econ\n",
      "[\"Don't know\", 'Yes', 'No']\n",
      "potential answers for climatechange\n",
      "['Climate changing due to human activity', \"Don't know\", 'Climate not changing', 'Climate changing but not due to human activity']\n",
      "potential answers for envirogrowth\n",
      "[\"Don't know\", 'Protecting the environment should have priority', 'Economic growth should have priority']\n",
      "potential answers for selfpriorities_environment\n",
      "[\"Don't know\", 'Yes', 'No']\n",
      "potential answers for immigcultural\n",
      "['Enriches cultural life', \"Don't know\", 'Undermines cultural life']\n",
      "potential answers for immigself\n",
      "[\"Don't know\", 'Allow many fewer', 'Allow many more']\n",
      "potential answers for changeimmig\n",
      "['Staying about the same', \"Don't know\", 'Getting a lot higher', 'Getting a lot lower', 'Getting a little lower', 'Getting a little higher']\n",
      "potential answers for immigecon\n",
      "['Good for economy', 'Bad for economy', \"Don't know\"]\n",
      "potential answers for controlimmig\n",
      "['A little control', 'Some control', 'No control at all', \"Don't know\", 'A lot of control', 'Complete control']\n",
      "potential answers for selfpriorities_nhs\n",
      "[\"Don't know\", 'Yes', 'No']\n",
      "potential answers for effectseunhs\n",
      "['Worse', 'Better', \"Don't know\", 'About the same', 'Much worse', 'Much better']\n",
      "potential answers for changenhs\n",
      "['Getting a lot worse', 'Getting a little worse', 'Getting a lot better', 'Staying about the same', 'Getting a little better', \"Don't know\"]\n",
      "potential answers for euintegrationself\n",
      "['Unite fully with the European Union', 'Protect our independence', \"Don't know\"]\n",
      "potential answers for cantlivewitheu_1\n",
      "['Acceptable', \"Don't know\", 'Unacceptable']\n",
      "potential answers for cantlivewitheu_2\n",
      "['Acceptable', 'Unacceptable', \"Don't know\"]\n",
      "potential answers for cantlivewitheu_3\n",
      "['Acceptable', 'Unacceptable', \"Don't know\"]\n",
      "potential answers for cantlivewitheu_4\n",
      "['Unacceptable', 'Acceptable', \"Don't know\"]\n",
      "potential answers for selfpriorities_brexit\n",
      "[\"Don't know\", 'Yes', 'No']\n",
      "potential answers for eurefvote\n",
      "['Stay/remain in the EU', 'Leave the EU', 'I would/will not vote', \"Don't know\"]\n",
      "potential answers for dealvremain\n",
      "['Remain in the EU', \"The government's withdrawal deal\", \"Don't know\", 'I would not vote']\n",
      "potential answers for remainvnodeal\n",
      "[\"Don't know\", 'Leave without a deal', 'Remain in the EU', 'I would not vote']\n",
      "potential answers for effectseuunemployment\n",
      "['Much higher', 'Higher', 'Lower', 'About the same', \"Don't know\", 'Much lower']\n",
      "potential answers for effectseutrade\n",
      "['About the same', 'Much higher', 'Lower', 'Higher', \"Don't know\", 'Much lower']\n",
      "potential answers for effectseuimmigration\n",
      "['About the same', 'Lower', 'Higher', \"Don't know\", 'Much lower', 'Much higher']\n",
      "potential answers for effectseuterror\n",
      "['Higher', 'About the same', \"Don't know\", 'Lower', 'Much higher', 'Much lower']\n",
      "potential answers for effectseuecon\n",
      "['Worse', 'About the same', 'Better', \"Don't know\", 'Much worse', 'Much better']\n",
      "potential answers for dealgoodbad\n",
      "[\"Don't know\", 'Neither good nor bad', 'Bad', 'Very bad', 'Good', 'Very good']\n",
      "potential answers for happyeuleave\n",
      "['Extremely disappointed', \"Don't know\", 'Extremely happy']\n",
      "potential answers for euid\n",
      "['The remain side', 'The leave side', \"Don't know\", 'Neither']\n",
      "potential answers for eurefdoover\n",
      "['Yes', 'No', \"Don't know\"]\n",
      "potential answers for cancelbrexit\n",
      "['Disagree', 'Strongly disagree', 'Strongly agree', 'Agree', \"Don't know\", 'Neither agree nor disagree']\n",
      "total list of answers:\n",
      "['Labour', 'No - none', 'Liberal Democrat', 'Conservative', 'Plaid Cymru', 'Brexit Party', \"Don't know\", 'Green Party', 'Scottish National Party (SNP)', 'Other', 'It is important but not absolutely  necessary', 'It is not necessary but it would be desirable', 'It is completely necessary', 'It is completely unnecessary', 'Disagree', 'Neither agree nor disagree', 'Strongly agree', 'Agree', 'Strongly disagree', 'Getting a lot worse', 'Staying about the same', 'Getting a little worse', 'Getting a lot better', 'Getting a little better', 'Got a little worse', 'Stayed the same', 'Got a lot worse', 'Got a little better', 'Got a lot better', 'A great deal', 'A moderate amount', 'Don\\x92t know', 'A lot', 'A little', 'Not at all', 'Yes', 'No', 'Climate changing due to human activity', 'Climate not changing', 'Climate changing but not due to human activity', 'Protecting the environment should have priority', 'Economic growth should have priority', 'Enriches cultural life', 'Undermines cultural life', 'Allow many fewer', 'Allow many more', 'Getting a lot higher', 'Getting a lot lower', 'Getting a little lower', 'Getting a little higher', 'Good for economy', 'Bad for economy', 'A little control', 'Some control', 'No control at all', 'A lot of control', 'Complete control', 'Worse', 'Better', 'About the same', 'Much worse', 'Much better', 'Unite fully with the European Union', 'Protect our independence', 'Acceptable', 'Unacceptable', 'Stay/remain in the EU', 'Leave the EU', 'I would/will not vote', 'Remain in the EU', \"The government's withdrawal deal\", 'I would not vote', 'Leave without a deal', 'Much higher', 'Higher', 'Lower', 'Much lower', 'Neither good nor bad', 'Bad', 'Very bad', 'Good', 'Very good', 'Extremely disappointed', 'Extremely happy', 'The remain side', 'The leave side', 'Neither']\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for col in extracted_data.columns:\n",
    "    \n",
    "    answersforcol =[]\n",
    "    count = 0\n",
    "    for i in extracted_data[col]:\n",
    "        i=str(i)\n",
    "        if i not in answersforcol and not i.isdigit() and \".\" not in i:#is digit removes ints . removes floats if someones put a . in there written answer fuckem\n",
    "            answersforcol.append(i)\n",
    "    \n",
    "        if i not in answers and not i.isdigit() and \".\" not in i:\n",
    "            answers.append(i)\n",
    "        count+=1\n",
    "        if count > 300:\n",
    "            break\n",
    "    print(\"potential answers for \"+str(col))\n",
    "    print(answersforcol)\n",
    "\n",
    "print(\"total list of answers:\")\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually sort prefixes\n",
    "prefixes = [['nan','It is completely necessary', 'It is important but not absolutely  necessary', 'It is not necessary but it would be desirable', \"Don't know\",  'It is completely unnecessary'],\n",
    "['Strongly disagree','Disagree', 'Neither agree nor disagree', 'Agree', 'Strongly agree',  \"Don't know\"]]\n",
    "\n",
    "def listoverlap(list1,list2):\n",
    "    for i in list1:\n",
    "        if i in list2:\n",
    "            \n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "linguisticprefixes = ['Strongly',\"much\",\"lot\",\"little\",\"bad\",\"good\",\"very\",\"extremely\",\"neither\",\"higher\",\"lower\",\"moderate\",\"absolutely\", 'worse', 'better', 'about the same','A little',\"Enriches\",\"Undermines\",\"many\",\"fewer\",\"more\"]\n",
    "problemwords = [\"not\",\"disagree\"]\n",
    "for i in range(len(linguisticprefixes)):\n",
    "    linguisticprefixes[i]=linguisticprefixes[i].lower()\n",
    "\n",
    "answersnopre = []\n",
    "for i in answers:\n",
    "    i = str(i)\n",
    "    i=i.lower()\n",
    "    contains = False\n",
    "    for k in linguisticprefixes:\n",
    "        if k in i:\n",
    "            contains = True\n",
    "    if not contains:\n",
    "        \n",
    "        answersnopre.append(i)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['partyid', 'deficitreduce', 'overseasaid', 'changeeconomy', 'econgenretro', 'econpersonalretro', 'economyresponsible', 'selfpriorities_econ', 'climatechange', 'envirogrowth', 'selfpriorities_environment', 'immigcultural', 'immigself', 'changeimmig', 'immigecon', 'controlimmig', 'selfpriorities_nhs', 'effectseunhs', 'changenhs', 'euintegrationself', 'cantlivewitheu_1', 'cantlivewitheu_2', 'cantlivewitheu_3', 'cantlivewitheu_4', 'selfpriorities_brexit', 'eurefvote', 'dealvremain', 'remainvnodeal', 'effectseuunemployment', 'effectseutrade', 'effectseuimmigration', 'effectseuterror', 'effectseuecon', 'dealgoodbad', 'happyeuleave', 'euid', 'eurefdoover', 'cancelbrexit']\n",
      "['envirogrowth']\n",
      "['envirogrowth', 'immigcultural']\n",
      "['envirogrowth', 'immigcultural', 'immigself']\n",
      "['envirogrowth', 'immigcultural', 'immigself', 'immigecon']\n",
      "['envirogrowth', 'immigcultural', 'immigself', 'immigecon', 'euintegrationself']\n",
      "['envirogrowth', 'immigcultural', 'immigself', 'immigecon', 'euintegrationself', 'happyeuleave']\n",
      "envirogrowth\n",
      "immigcultural\n",
      "immigself\n",
      "immigecon\n",
      "euintegrationself\n",
      "happyeuleave\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "can probably be sorted:\n",
      "['changeeconomy', 'econpersonalretro', 'changeimmig', 'effectseunhs', 'effectseuunemployment', 'effectseuimmigration', 'effectseuecon', 'euid', 'immigcultural_text', 'immigecon_text', 'happyeuleave_text']\n",
      "gonna require manual sorting:\n",
      "['deficitreduce', 'cancelbrexit']\n",
      "can be 1 hot encoded:\n",
      "['partyid', 'overseasaid', 'econgenretro', 'economyresponsible', 'selfpriorities_econ', 'climatechange', 'selfpriorities_environment', 'controlimmig', 'selfpriorities_nhs', 'changenhs', 'cantlivewitheu_1', 'cantlivewitheu_2', 'cantlivewitheu_3', 'cantlivewitheu_4', 'selfpriorities_brexit', 'eurefvote', 'dealvremain', 'remainvnodeal', 'effectseutrade', 'effectseuterror', 'dealgoodbad', 'eurefdoover', 'envirogrowth_text', 'immigself_text', 'euintegrationself_text']\n",
      "already numeric\n",
      "['envirogrowth_numeric', 'immigcultural_numeric', 'immigself_numeric', 'immigecon_numeric', 'euintegrationself_numeric', 'happyeuleave_numeric']\n"
     ]
    }
   ],
   "source": [
    "#sorts the collums\n",
    "extracted_data = originaldata\n",
    "\n",
    "colnames = []\n",
    "for i in extracted_data.columns:\n",
    "    colnames.append(str(i))\n",
    "print(colnames)\n",
    "\n",
    "orderedcolumns = []\n",
    "columnsneedmanualsorting = []\n",
    "onehotable = colnames#assumes all can be 1 hotted in beggining\n",
    "    \n",
    "\n",
    "alreadynumeric = []\n",
    "#checks if answers already in numerical form\n",
    "for col in list(onehotable):\n",
    "   \n",
    "    count = 0\n",
    "    for i in extracted_data[col]:\n",
    "        i=str(i)\n",
    "        if i.isdigit() or \".\"  in i:#is digit removes ints . removes floats if someones put a . in there written answer fuckem\n",
    "            #print(i)\n",
    "            onehotable.remove(col)\n",
    "            alreadynumeric.append(col)\n",
    "            print(alreadynumeric)\n",
    "            \n",
    "            break\n",
    "        count+=1\n",
    "        if count > 300:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "numericandtext = []\n",
    "for col in list(alreadynumeric):#col colnames of collums with numbers\n",
    "    col =col.lower().strip()\n",
    "    count = 0\n",
    "\n",
    "    print(col)\n",
    "    for i in extracted_data[col]:\n",
    "        i=str(i)\n",
    "        #print(i)\n",
    "        if not i.isdigit() and not \".\"  in i:#if not digit must contain both\n",
    "            #print(col)\n",
    "            \n",
    "            alreadynumeric.remove(col)\n",
    "            numericandtext.append(col)\n",
    "            #print(col)\n",
    "            \n",
    "            break\n",
    "        count+=1\n",
    "        if count > 400:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "print(\"------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for col in numericandtext:\n",
    "    numericcol = []\n",
    "    textcol = []\n",
    "    for i in extracted_data[col]:\n",
    "        i=str(i)\n",
    "        if i.isdigit() or \".\"  in i:\n",
    "            #print(i)\n",
    "            \n",
    "            numericcol.append(i)\n",
    "            textcol.append(\"Don't know\")\n",
    "        else:\n",
    "            numericcol.append(\"5\")\n",
    "            textcol.append(i)\n",
    "    #print(extracted_data.columns)\n",
    "    extracted_data.drop(columns = col)\n",
    "    onehotable.append(col+\"_text\")\n",
    "    extracted_data[col+\"_text\"]=textcol\n",
    "    alreadynumeric.append(col+\"_numeric\")\n",
    "    extracted_data[col+\"_numeric\"] = numericcol\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "for col in colnames:\n",
    "    \n",
    "    count=0\n",
    "    for i in extracted_data[col]:\n",
    "        i=str(i).lower()\n",
    "        \n",
    "        if(listoverlap(i.split(),linguisticprefixes)):#checks for overlap between lists\n",
    "            \n",
    "            orderedcolumns.append(col)\n",
    "            onehotable.remove(col)#if needs sorting cannot be 1 hotted\n",
    "            break#break if found atleast one instance of words that need ordering\n",
    "        count+=1\n",
    "        if count> 1000:\n",
    "            break\n",
    "\n",
    "\n",
    "for col in list(orderedcolumns):\n",
    "    for k in extracted_data[col]:\n",
    "        k=str(k).lower()\n",
    "        if listoverlap(k.split(),problemwords):\n",
    "            orderedcolumns.remove(str(col))\n",
    "            columnsneedmanualsorting.append(col)\n",
    "            break\n",
    "        \n",
    "            #if data contains problem words algorithm wont work so we need to sort it manually\n",
    "            #simplest example is not\n",
    "            #very very good > very good\n",
    "            #but very very very not good > very very good\n",
    "            #could maybe solve with a -1 term somwhere seems to complicated though\n",
    "                \n",
    "            \n",
    "\n",
    "print(\"can probably be sorted:\")\n",
    "print(orderedcolumns)\n",
    "print(\"gonna require manual sorting:\")\n",
    "print(columnsneedmanualsorting)\n",
    "print(\"can be 1 hot encoded:\")\n",
    "print(onehotable)\n",
    "print(\"already numeric\")\n",
    "print(alreadynumeric)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential answers for envirogrowth_numeric\n",
      "['8', '5', '1', '6', '9', '7', '2', '3', '4']\n",
      "potential answers for immigcultural_numeric\n",
      "['5', '3', '6', '4', '2']\n",
      "potential answers for immigself_numeric\n",
      "['7', '4', '5', '2', '6', '1', '8', '3', '9']\n",
      "potential answers for immigecon_numeric\n",
      "['5', '4', '6', '2', '3']\n",
      "potential answers for euintegrationself_numeric\n",
      "['5', '7', '3', '1', '2', '8', '9', '4', '6']\n",
      "potential answers for happyeuleave_numeric\n",
      "['2.0', '9.0', '5', '1.0', '3.0', '5.0', '7.0', '8.0', '4.0', '6.0']\n",
      "total list of answers:\n",
      "['8', '5', '1', '6', '9', '7', '2', '3', '4', '2.0', '9.0', '1.0', '3.0', '5.0', '7.0', '8.0', '4.0', '6.0']\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for col in alreadynumeric:\n",
    "    \n",
    "    answersforcol =[]\n",
    "    count = 0\n",
    "    for i in extracted_data[col]:\n",
    "        i=str(i)\n",
    "        if i not in answersforcol:#is digit removes ints . removes floats if someones put a . in there written answer fuckem\n",
    "            answersforcol.append(i)\n",
    "    \n",
    "        if i not in answers:\n",
    "            answers.append(i)\n",
    "        count+=1\n",
    "        if count > 300:\n",
    "            break\n",
    "    print(\"potential answers for \"+str(col))\n",
    "    print(answersforcol)\n",
    "\n",
    "print(\"total list of answers:\")\n",
    "print(answers)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers:\n",
      "['no - none', 'labour', 'liberal democrat', 'conservative', 'plaid cymru', 'brexit party', \"don't know\", 'green party', 'scottish national party (snp)', 'other', 'united kingdom independence party (ukip)', 'disagree', 'agree', 'stayed the same', 'a great deal', 'don\\x92t know', 'not at all', 'yes', 'no', 'climate changing due to human activity', 'climate not changing', 'climate changing but not due to human activity', 'some control', 'no control at all', 'complete control', 'staying about the same', 'acceptable', 'unacceptable', 'stay/remain in the eu', 'leave the eu', 'i would/will not vote', 'remain in the eu', \"the government's withdrawal deal\", 'i would not vote', 'leave without a deal', 'about the same', 'protecting the environment should have priority', 'economic growth should have priority', 'unite fully with the european union', 'protect our independence']\n"
     ]
    }
   ],
   "source": [
    "onehotanswers = [\"no - none\"]\n",
    "\n",
    "#print(linguisticprefixes)\n",
    "\n",
    "arr = []\n",
    "for col in onehotable:\n",
    "    \n",
    "    count = 0\n",
    "    for k in extracted_data[col]:\n",
    "        k=str(k)\n",
    "        k=k.lower()\n",
    "        count +=1\n",
    "        #if(set(onehotanswers).isdisjoint(k.split())):\n",
    "            #onehotanswers.append(k)\n",
    "        if not listoverlap(k.split(),linguisticprefixes):\n",
    "\n",
    "            #print(k)\n",
    "            #print(col)   \n",
    "            #arr.append((k,col))\n",
    "            onehotanswers.append(k)\n",
    "        if count> 1000:\n",
    "            break\n",
    "onehotanswers = list(dict.fromkeys(onehotanswers))\n",
    "#print(arr)\n",
    "print(\"answers:\")\n",
    "print(onehotanswers)\n",
    "#these can be done using scikit label thing\n",
    "\n",
    "#check this for stuff needed to be added to linguistic prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linguisticprefixes =['Strongly',\"much\",\"lot\",\"little\",\"bad\",\"good\",\"very\",\"extremely\",\"neither\",\"higher\",\"lower\",\"moderate\",\"absolutely\", 'worse', 'better', 'about the same','A little',\"Enriches\"\n",
    ",\"Undermines\",\"many\",\"fewer\",\"more\"]\n",
    "lmultipliers = ['Strongly',\"much\",\"lot\",\"extremely\",\"very\",\"extremely\",\"absolutely\",\"more\"]#strong multipliers\n",
    "#could split strong multipliers theres never more then 1 in a \n",
    "smultipliers = [\"little\",\"fewer\"]#weak multipliers\n",
    "\n",
    "posadd =[\"good\",\"better\",\"Enriches\"]#map to 0>\n",
    "negadd = [\"bad\",\"lower\",\"worse\",\"Undermines\"]#map to 0<\n",
    "zadd =[\"about the same\"]#map to 0\n",
    "\n",
    "# linguisticprefixes = lmultipliers+smultiplier+posadd+zadd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data.columns= extracted_data.columns.str.strip().str.lower()\n",
    "#for i in extracted_data.columns:\n",
    "    #print(i)\n",
    "\n",
    "orderable = extracted_data[orderedcolumns].copy()\n",
    "y = 0\n",
    "newdf = pd.DataFrame()\n",
    "for col in orderable.columns:\n",
    "    print(len(orderable[col]))    \n",
    "    x=0\n",
    "    colvals = []\n",
    "    for i in orderable[col]:\n",
    "        x+=1\n",
    "        val=1\n",
    "        i = str(i).lower()\n",
    "        if not i.isdigit():\n",
    "            i=i.split()\n",
    "            if listoverlap(i,zadd):\n",
    "                val = 0\n",
    "            if listoverlap(i,posadd):\n",
    "                val +=2\n",
    "            if listoverlap(i,negadd):\n",
    "                val -=2          \n",
    "            if listoverlap(i,lmultipliers):\n",
    "                val = val*2\n",
    "            if listoverlap(i,smultipliers):\n",
    "                val = val*1/2\n",
    "            #orderable[col].replace({str(i),val})\n",
    "            colvals.append(val)\n",
    "            if x % 50 == 0:\n",
    "                print((x,y))\n",
    "    #print(colvals)\n",
    "    newdf[col]=colvals\n",
    "    y+=1\n",
    "    \n",
    "\n",
    "\n",
    "from pathlib import Path  \n",
    "filepath = Path('orderable_columns_ordered.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "newdf.to_csv(filepath)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_unique_parites = extracted_data['partyId'].unique()\n",
    "list_unique_parties = list(list_unique_parites)\n",
    "party_sums = []\n",
    "for i in range(len(list_unique_parites)):\n",
    "    count = 0 \n",
    "    for x in (extracted_data['partyId'] == list_unique_parites[i]):\n",
    "        if x == True:\n",
    "            count += 1\n",
    "    party_sums.append(count)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_data = {'Parties':list_unique_parites,'Count':party_sums}\n",
    "data_parties = pd.DataFrame(party_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages =[]\n",
    "for i in data_parties['Count']:\n",
    "    percentages.append(int(i)/data_parties.sum()*100)\n",
    "\n",
    "data_parties['Percentages']= percentages\n",
    "data_parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.pie(data_parties['Count'],labels = data_parties['Parties'],shadow = False)\n",
    "plt.figure(facecolor=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-prototype clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_modes_data = extracted_data.drop(['partyId','enviroGrowth','immigCultural','immigSelf','immigEcon','EUIntegrationSelf','happyEULeave'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_modes_data_matrix = k_modes_data.to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmodes.kmodes import KModes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = []\n",
    "for cluster in range(1, 11):\n",
    "    kmodes = KModes(n_clusters = cluster, init = 'Huang', random_state = 0)\n",
    "    kmodes.fit_predict(k_modes_data_matrix)\n",
    "    cost.append(kmodes.cost_)\n",
    "    print('Cluster initiation: {}'.format(cluster))\n",
    "  \n",
    "print(len(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cost = pd.DataFrame({'Cluster': range(1, 11), 'Cost': cost})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "import plotnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plotnine.options.figure_size = (8, 4.8)\n",
    "(\n",
    "    ggplot(data = df_cost)+\n",
    "    geom_line(aes(x = 'Cluster',\n",
    "                  y = 'Cost'))+\n",
    "    geom_point(aes(x = 'Cluster',\n",
    "                   y = 'Cost'))+\n",
    "    geom_label(aes(x = 'Cluster',\n",
    "                   y = 'Cost',\n",
    "                   label = 'Cluster'),\n",
    "               size = 10,\n",
    "               nudge_y = 1000) +\n",
    "    labs(title = 'Optimal number of cluster with Elbow Method')+\n",
    "    xlab('Number of Clusters k')+\n",
    "    ylab('Cost')+\n",
    "    theme_minimal()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmodes = KModes(n_jobs = -1, n_clusters = 6, init = 'Huang', random_state = 0)\n",
    "kmodes.fit_predict(k_modes_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data['Cluster Labels'] = kmodes.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments_cluster_0 =[]\n",
    "assignments_cluster_1 =[]\n",
    "assignments_cluster_2 =[]\n",
    "assignments_cluster_3 =[]\n",
    "assignments_cluster_4 =[]\n",
    "assignments_cluster_5 =[]\n",
    "for x in range(len(extracted_data['partyId'])):\n",
    "    if extracted_data.loc[x,'Cluster Labels'] == 0:\n",
    "        assignments_cluster_0.append(extracted_data.loc[x,'partyId'])\n",
    "    elif extracted_data.loc[x,'Cluster Labels'] == 1:\n",
    "        assignments_cluster_1.append(extracted_data.loc[x,'partyId'])\n",
    "    elif extracted_data.loc[x,'Cluster Labels'] == 2:\n",
    "        assignments_cluster_2.append(extracted_data.loc[x,'partyId'])\n",
    "    elif extracted_data.loc[x,'Cluster Labels'] == 3:\n",
    "        assignments_cluster_3.append(extracted_data.loc[x,'partyId'])\n",
    "    elif extracted_data.loc[x,'Cluster Labels'] == 4:\n",
    "        assignments_cluster_4.append(extracted_data.loc[x,'partyId'])\n",
    "    else:\n",
    "        assignments_cluster_5.append(extracted_data.loc[x,'partyId'])\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster1 = pd.DataFrame({'Assignments': assignments_cluster_5})\n",
    "Cluster1['Assignments'].value_counts()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62c95e99237af2378f1ef5afb241d0a0f8e6d9f52b046f51f6de2dd208ad2ab4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
